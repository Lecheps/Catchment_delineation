{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic catchment delineation using python and postgis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading required modules\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "import psycopg2 as db\n",
    "import psycopg2.extras\n",
    "from psycopg2 import sql\n",
    "from encrypt import decryptCredentials,decryptString\n",
    "from procedures import refreshProcedures\n",
    "import yaml\n",
    "import getpass\n",
    "\n",
    "from pygments import highlight\n",
    "from pygments.formatters import HtmlFormatter\n",
    "from pygments.lexers import YamlLexer\n",
    "from IPython.core.display import display,HTML\n",
    "\n",
    "import json\n",
    "import gmaps\n",
    "import gmaps.geojson_geometries\n",
    "import geojson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-requisites\n",
    "\n",
    "The name of the geodatabase is *Basins_HWI*\n",
    "A schema called _norway_ should be created beforehand in the geodatabase.\n",
    "\n",
    "Both rivers and dems can be uploaded to the database to dynamically generated tables using code in this notebook.\n",
    "This should only be done once since it is a time-consuming operation.\n",
    "\n",
    "For future reference, these are some of the commands used to create the database:\n",
    "```\n",
    "\n",
    "cursor.execute('ALTER DATABASE \\\"Basins_HWI\\\" SET search_path=public, postgis, contrib,topology;')\n",
    "cursor.execute('ALTER DATABASE \\\"Basins_HWI\\\" SET postgis.gdal_enabled_drivers = \\'ENABLE_ALL\\';')\n",
    "cursor.execute('CREATE EXTENSION postgis;')\n",
    "cursor.execute('CREATE EXTENSION postgis_topology;')\n",
    "cursor.execute('ALTER DATABASE \\\"Basins_HWI\\\" SET search_path=public, postgis, contrib,topology;')\n",
    "cursor.execute('ALTER DATABA \\\"Basins_HWI\\\" SET postgis.gdal_enabled_drivers = \\'ENABLE_ALL\\';')\n",
    "cursor.execute('SELECT pg_reload_conf();')\n",
    "cursor.execute('SET postgis.enable_outdb_rasters TO True;')\n",
    "```\n",
    "\n",
    "The operations required to organize the elevation and river data datasets necessary to perform the catchment delineation have been (partially) stored in the geodatabase as stored procedures. These stored procedures are defined in the _procedures.py_ file in this repository.\n",
    "\n",
    "\n",
    "### Elevation data\n",
    "\n",
    "Elevation data should be downloaded from Kartverket. This has not yet been done for all of Norway but for parts of it. It might be possible to use some automation but this has been done by pointing and clicking. \n",
    "\n",
    "10m resolution dem have been used.\n",
    "\n",
    "Some remarks regarding raster upload:\n",
    "\n",
    "* So far rasters have been uploaded for the following projections:\n",
    "    * EPSG:32633\n",
    "    * EPSG:32632\n",
    "\n",
    "* Any additional projections are not automagically handled.\n",
    "\n",
    "* When uploading rasters to a table, make sure the first uploaded raster has the largest extent. Othewise, strange things happen. I haven't figured out why. Also avoid underscores in the raster files that are uploaded. Tile the uploaded raster otherwise queries become slow.\n",
    "\n",
    "\n",
    "The dems having a common projection were uploaded to separate tables in the _norway_ schema.\n",
    "* _norway.dem32_ (for utm 32 data)\n",
    "* _norway.dem33_ (for utm 33 data)\n",
    "\n",
    "### River shapefiles\n",
    "\n",
    "The river shapefiles was downloaded from NVE and uploaded geodatabase to _norway_ in a table called _norway.rivers _ .\n",
    "\n",
    "### Postgis database\n",
    "\n",
    "Postgresql 5.5 with Postgis 2.4 have been used.\n",
    "Postgis might need to be explicitly enabled.\n",
    "\n",
    "The name of the geodatabase is *Basins_HWI*\n",
    "\n",
    "\n",
    "#### Connection credentials\n",
    "\n",
    "The credentials necessary to connect to the database have been encrypted using the _cryptography_ package.\n",
    "The encryption and decryption functions are defined in the _encrypt.py_ file of this repository.\n",
    "\n",
    "### Taudem\n",
    "\n",
    "The catchment delineation routines come from the [Taudem](http://hydrology.usu.edu/taudem/taudem5/index.html) package. The package's routines should be installed and available from the path.\n",
    "\n",
    "## Catchment delineation\n",
    "\n",
    "### Setting up credentials and connecting to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Password: ········\n"
     ]
    }
   ],
   "source": [
    "#Setting up credentials for database access. These should have been previously encrypted\n",
    "token = b'gAAAAABaVgNb96o6n1Kixc3fHKQWyEPN7jnJvXv_NJs65yjvJDqZZOH4w9aTyYJD28kx3iJr4EG0nsqTgxv_PRCOPKjkGPlQHycz8BuRTr25vETKiPAbLT28CJWLYLnWMllF_M1sGj_GErPOciHOQiraNUuo6IJMlVnUVMR5FvhP7YtqCKwtLSk0yefn4HU2fc6I5x1NNd94'\n",
    "key = getpass.getpass('Password: ')\n",
    "credentials = decryptCredentials(token,key)\n",
    "\n",
    "#Setting up credentials for google maps api access\n",
    "apiToken = b'gAAAAABaXyLsGnF3ms4sC3ZhoLCwWAx9q0tydWl8XKEwOy8CO0W6Eqc8J4om8HNDlNR9nExYCmSrelp8W5R-PLtcce1I2UgW3YnlXXqWvrMN-outYwXhZoc59djfF752mzOPqXBHgpNC'\n",
    "apiKey = decryptString(apiToken,key)\n",
    "gmaps.configure(api_key=apiKey)\n",
    "\n",
    "# Connecting to database\n",
    "try : \n",
    "    conn = db.connect(\"dbname={} user={} host={} password={}\".format(credentials['database'],credentials['username'],credentials['host'],credentials['password']))\n",
    "except :\n",
    "    print(\"Unable to connect\")\n",
    "    \n",
    "cursor = conn.cursor()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refreshing stored procedures\n",
    "\n",
    "This is necessary if the procedures defined in _procedures.py_ are modified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refreshing stored procedures if necessary.\n",
    "refresh = True\n",
    "if refresh :\n",
    "    refreshProcedures(credentials['database'],credentials['username'],credentials['host'],credentials['password'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing rivers in database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding shapefile containing all of Norway's rivers    \n",
    "#Shapefile info and schema.table where they will be stored\n",
    "addRivers = False\n",
    "riversShp = '/home/jose-luis/Documents/GeoData/RiversNVE/Elv_Elvenett.shp'\n",
    "epsg_num = 3006 #epsg number for the shapefile, failed to obtain it programatically\n",
    "schema = 'norway'\n",
    "table = 'rivers'\n",
    "\n",
    "rivers_cmd = \"shp2pgsql -I -d -s {} {} {}.{}\"\n",
    "psql_cmd = \"PGPASSWORD={} psql -U {} -d {} -h {} -p 5432 -q\"\n",
    "\n",
    "#The loadRivers() procedureas add a shapefile to the table using shp2pgsql\n",
    "if addRivers :\n",
    "        print(\"Loading all norwegian rivers...\")\n",
    "#        cursor.execute(\"SELECT procedures.loadRivers(%s,%s,%s,%s);\", (riversShp, epsg_number, schema, table ) )\n",
    "#        conn.commit()\n",
    "        subprocess.check_call(rivers_cmd.format(epsg_num,riversShp, schema, table ) + ' | ' + \\\n",
    "                      psql_cmd.format(credentials['password'],credentials['username'],credentials['database'],credentials['host']), \\\n",
    "                      shell=True, stdout=open(os.devnull, 'wb') ) \n",
    "        print(\"Done!\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing dem's in database\n",
    "\n",
    "Currently they should all be placed in a common folder. The projection is currently deduced from the file name, taking advantage of Kartverket naming convention (ends with _z32_ for UTM 32 and with _z33_ for UTM 33). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "addDEM = False\n",
    "folderDEM = '/home/jose-luis/Documents/GeoData/DEM'\n",
    "schema = 'norway'     \n",
    "load_cmd = \"raster2pgsql -I -C -M -b 1 -r -s {} -d -t 10x10 {}/*z{}.tif {}.{}\"\n",
    "psql_cmd = \"PGPASSWORD={} psql -U {} -d {} -h {} -p 5432 -q\"\n",
    "\n",
    "if addDEM :\n",
    "    print(\"Loading all elevation rasters in folder {}\".format(folderDEM))\n",
    "    table = 'demutm32'\n",
    "    epsg_num = 32632\n",
    "    subprocess.check_call(load_cmd.format(epsg_num, folderDEM, str(epsg_num)[-2:], schema, table ) + ' | ' + \\\n",
    "                          psql_cmd.format(credentials['password'],credentials['username'],credentials['database'],credentials['host']), \\\n",
    "                          shell=True, stdout=open(os.devnull, 'wb') ) \n",
    "    cursor.execute(\"SELECT procedures.setExtentTable(%s,%s);\",(schema,epsg_num))\n",
    "    conn.commit()\n",
    "    table = 'demutm33'\n",
    "    epsg_num = 32633\n",
    "    subprocess.check_call(load_cmd.format(epsg_num,folderDEM,str(epsg_num)[-2:], schema, table ) + ' | ' + \\\n",
    "                      psql_cmd.format(credentials['password'],credentials['username'],credentials['database'],credentials['host']), \\\n",
    "                      shell=True, stdout=open(os.devnull, 'wb') ) \n",
    "\n",
    "    cursor.execute(\"SELECT procedures.setExtentTable(%s,%s);\",(schema,epsg_num))\n",
    "    conn.commit()\n",
    "    print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting outlets for catchment delineation\n",
    "As many catchment as there are outlets will be delineated. The outlets should be given in _.yaml_ file with the following format:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\"><pre><span></span><span class=\"p p-Indicator\">-</span> <span class=\"l l-Scalar l-Scalar-Plain\">station</span><span class=\"p p-Indicator\">:</span>\n",
       "    <span class=\"l l-Scalar l-Scalar-Plain\">station_id</span><span class=\"p p-Indicator\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">221</span>\n",
       "    <span class=\"l l-Scalar l-Scalar-Plain\">station_name</span><span class=\"p p-Indicator\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">Birkenes</span>\n",
       "    <span class=\"l l-Scalar l-Scalar-Plain\">longitude</span><span class=\"p p-Indicator\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">8.2417211373</span>\n",
       "    <span class=\"l l-Scalar l-Scalar-Plain\">latitude</span><span class=\"p p-Indicator\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">58.3854261264</span>\n",
       "    <span class=\"l l-Scalar l-Scalar-Plain\">epsg</span><span class=\"p p-Indicator\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">4326</span>\n",
       "    <span class=\"l l-Scalar l-Scalar-Plain\">buffer</span><span class=\"p p-Indicator\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">2000</span>   <span class=\"c1\">#in meters</span>\n",
       "\n",
       "<span class=\"p p-Indicator\">-</span> <span class=\"l l-Scalar l-Scalar-Plain\">station</span><span class=\"p p-Indicator\">:</span>\n",
       "    <span class=\"l l-Scalar l-Scalar-Plain\">station_id</span><span class=\"p p-Indicator\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">12025</span>\n",
       "    <span class=\"l l-Scalar l-Scalar-Plain\">station_name</span><span class=\"p p-Indicator\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">Øygardsbekken</span>\n",
       "    <span class=\"l l-Scalar l-Scalar-Plain\">longitude</span><span class=\"p p-Indicator\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">6.1064093305</span>\n",
       "    <span class=\"l l-Scalar l-Scalar-Plain\">latitude</span><span class=\"p p-Indicator\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">58.621933418</span>\n",
       "    <span class=\"l l-Scalar l-Scalar-Plain\">epsg</span><span class=\"p p-Indicator\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">4326</span>\n",
       "    <span class=\"l l-Scalar l-Scalar-Plain\">buffer</span><span class=\"p p-Indicator\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">2000</span>\n",
       "\n",
       "<span class=\"p p-Indicator\">-</span> <span class=\"l l-Scalar l-Scalar-Plain\">station</span><span class=\"p p-Indicator\">:</span>\n",
       "    <span class=\"l l-Scalar l-Scalar-Plain\">station_id</span><span class=\"p p-Indicator\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">12080</span>\n",
       "    <span class=\"l l-Scalar l-Scalar-Plain\">station_name</span><span class=\"p p-Indicator\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">Storgama v. dam</span>\n",
       "    <span class=\"l l-Scalar l-Scalar-Plain\">longitude</span><span class=\"p p-Indicator\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">8.6536063505</span>\n",
       "    <span class=\"l l-Scalar l-Scalar-Plain\">latitude</span><span class=\"p p-Indicator\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">59.0523331551</span>\n",
       "    <span class=\"l l-Scalar l-Scalar-Plain\">epsg</span><span class=\"p p-Indicator\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">4326</span>\n",
       "    <span class=\"l l-Scalar l-Scalar-Plain\">buffer</span><span class=\"p p-Indicator\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">2000</span>\n",
       "\n",
       "<span class=\"p p-Indicator\">-</span> <span class=\"l l-Scalar l-Scalar-Plain\">station</span><span class=\"p p-Indicator\">:</span>\n",
       "    <span class=\"l l-Scalar l-Scalar-Plain\">station_id</span><span class=\"p p-Indicator\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">12081</span>\n",
       "    <span class=\"l l-Scalar l-Scalar-Plain\">station_name</span><span class=\"p p-Indicator\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">Kårvatn</span>\n",
       "    <span class=\"l l-Scalar l-Scalar-Plain\">longitude</span><span class=\"p p-Indicator\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">8.8934427312</span>\n",
       "    <span class=\"l l-Scalar l-Scalar-Plain\">latitude</span><span class=\"p p-Indicator\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">62.7828833564</span>\n",
       "    <span class=\"l l-Scalar l-Scalar-Plain\">epsg</span><span class=\"p p-Indicator\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">4326</span>\n",
       "    <span class=\"l l-Scalar l-Scalar-Plain\">buffer</span><span class=\"p p-Indicator\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">10000</span>\n",
       "\n",
       "<span class=\"p p-Indicator\">-</span> <span class=\"l l-Scalar l-Scalar-Plain\">station</span><span class=\"p p-Indicator\">:</span>\n",
       "    <span class=\"l l-Scalar l-Scalar-Plain\">station_id</span><span class=\"p p-Indicator\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">12082</span>\n",
       "    <span class=\"l l-Scalar l-Scalar-Plain\">station_name</span><span class=\"p p-Indicator\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">Dalelv</span>\n",
       "    <span class=\"l l-Scalar l-Scalar-Plain\">longitude</span><span class=\"p p-Indicator\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">30.3861541427</span>\n",
       "    <span class=\"l l-Scalar l-Scalar-Plain\">latitude</span><span class=\"p p-Indicator\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">69.6847380767</span>\n",
       "    <span class=\"l l-Scalar l-Scalar-Plain\">epsg</span><span class=\"p p-Indicator\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">4326</span>\n",
       "    <span class=\"l l-Scalar l-Scalar-Plain\">buffer</span><span class=\"p p-Indicator\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">2000</span>\n",
       "\n",
       "<span class=\"p p-Indicator\">-</span> <span class=\"l l-Scalar l-Scalar-Plain\">station</span><span class=\"p p-Indicator\">:</span>\n",
       "    <span class=\"l l-Scalar l-Scalar-Plain\">station_id</span><span class=\"p p-Indicator\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">108</span>\n",
       "    <span class=\"l l-Scalar l-Scalar-Plain\">station_name</span><span class=\"p p-Indicator\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">Langtjern, utløp</span>\n",
       "    <span class=\"l l-Scalar l-Scalar-Plain\">longitude</span><span class=\"p p-Indicator\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">9.7266598416</span>\n",
       "    <span class=\"l l-Scalar l-Scalar-Plain\">latitude</span><span class=\"p p-Indicator\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">60.3724626431</span>\n",
       "    <span class=\"l l-Scalar l-Scalar-Plain\">epsg</span><span class=\"p p-Indicator\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">4326</span>\n",
       "    <span class=\"l l-Scalar l-Scalar-Plain\">buffer</span><span class=\"p p-Indicator\">:</span> <span class=\"l l-Scalar l-Scalar-Plain\">2500</span>\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stationsFile = 'stations.yaml'\n",
    "\n",
    "fid = open(stationsFile,'r')\n",
    "code = fid.read()\n",
    "fid.close\n",
    "result = highlight(code, YamlLexer(),HtmlFormatter(linenos=False))\n",
    "display(HTML(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The _.yaml_ file will be read and the above data stored as a table containing point geometries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding stations (coordinates) where the basins will be delineated\n",
    "#Reading station data from a yaml file\n",
    "stations = yaml.load(open(stationsFile))  \n",
    "db.extras.register_composite('station_info',cursor)\n",
    "\n",
    "#Re-arranging data as a list of tuples and passing it to pg with the help\n",
    "#of pyscopg2 extras\n",
    "allStations = list()\n",
    "for i in stations:\n",
    "    i=i['station']\n",
    "    data = ( i['station_name'],\n",
    "             i['station_id'],\n",
    "             i['longitude'],\n",
    "             i['latitude'],\n",
    "             i['buffer'],\n",
    "             i['epsg']\n",
    "           )\n",
    "    allStations.append(data)\n",
    "\n",
    "cursor.execute(\"SELECT procedures.initializeStations();\")\n",
    "conn.commit()\n",
    "\n",
    "cursor.execute(\"SELECT procedures.addStations( %s::station_info[] );\",(allStations,))\n",
    "conn.commit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gathering data for catchment delineation\n",
    "#### Initializing schema to store results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsSchema = 'basins'\n",
    "cursor.execute(\"SELECT procedures.initializeResultsSchema( %s );\",(resultsSchema,))\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gathering dem from a circular buffer around the station\n",
    "\n",
    "The Norway dem will be queried to get a the elevation in a circular buffer around the station. The size (radius) of the buffer is defined in the _.yaml_ file.\n",
    "\n",
    "The rivers shapefile will be clipped according to the extent of the buffered dem and burned into it prior to catchment delineation.\n",
    "\n",
    "The actual coordinates of the station will be modified so they fall on a river. The outlet will be set as the closest point between station coordinates and the rivers shapefile.\n",
    "\n",
    "Please note that both rivers, dems, and stations might come in different coordinate systems. This is automatically handled only for some projections.\n",
    "\n",
    "All the base data will be stored in a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading base data...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Getting raster around station\n",
    "\n",
    "#Creating table to store results\n",
    "dataTable = 'dem'\n",
    "cursor.execute(\" SELECT procedures.createDataTable(%s,%s,%s);\", (resultsSchema,dataTable,32632))\n",
    "conn.commit()\n",
    "cursor.execute(\" SELECT procedures.createDataTable(%s,%s,%s);\", (resultsSchema,dataTable,32633))\n",
    "conn.commit()\n",
    "\n",
    "#Getting buffer raster around station\n",
    "#Getting clipped rivers\n",
    "#Burning-in rivers\n",
    "#See procedures.py for details on the implementation\n",
    "print(\"Loading base data...\")\n",
    "cursor.execute(\"SELECT procedures.generateBaseData(%s,%s);\",(resultsSchema,32632));\n",
    "cursor.execute(\"SELECT procedures.generateBaseData(%s,%s);\",(resultsSchema,32633));\n",
    "conn.commit()\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catchment delineation\n",
    "\n",
    "Currently the results will be stored for each different available dem projection and the table names generated dynamically based on the projection's epsg number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating tables to store results. One table per dem projection\n",
    "resultsTable = 'results'\n",
    "cursor.execute(\"SELECT procedures.createResultsTable(%s,%s,%s);\",(resultsSchema,resultsTable,32632));\n",
    "cursor.execute(\"SELECT procedures.createResultsTable(%s,%s,%s);\",(resultsSchema,resultsTable,32633));\n",
    "conn.commit()\n",
    "\n",
    "#Creating folder to store intermediary results\n",
    "tempDir = './Trash/'\n",
    "if os.path.exists(tempDir) : \n",
    "    shutil.rmtree(tempDir)\n",
    "os.mkdir(tempDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing \n",
    "* _Taudem_ statements\n",
    "* *gdal_translate* statements to get raster from database as _.tif_. This will be an input to taudem.\n",
    "* _pgsql2psql_ to get each outlet as a shapefile that will be used to delineate the catchment by taudem.\n",
    "* _raster2pgsql_ to upload the watershed raster to the results table. The catchment is delineated from this dem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating strings for the taudem, raster2pgsql and shp2pgsql commands\n",
    "#Getting dem with burned-in rivers from database\n",
    "get_dem_cmd =           \"\"\"gdal_translate -of GTiff PG:\"host={} port='5432' dbname={} user={} password={} schema='{}' table='{}'  column='{}' where='{}' \" {} \"\"\"\n",
    "#Filling dem\n",
    "fill_cmd =              \"\"\"mpiexec -n 8 pitremove -z {} -fel {}\"\"\"\n",
    "#Computation of flow direction\n",
    "flow_dir_cmd=           \"\"\"mpiexec -n 8 d8flowdir -fel {} -p {}\"\"\"\n",
    "#Computation of flow accumulation\n",
    "flow_acc_cmd=           \"\"\"mpiexec -n 8 aread8 -p {}  -nc -ad8 {}\"\"\"\n",
    "#Getting outlet from database as a shapefile\n",
    "station_as_shp_cmd =    \"\"\"pgsql2shp -g outlet -f {} -h localhost -u {} -P {} {} \"SELECT a.station_name, a.station_id, a.outlet FROM {} AS a WHERE a.station_id={}\" \"\"\"\n",
    "#Delineating watershed\n",
    "watershed_cmd=          \"\"\"mpiexec -n 8 gagewatershed -p {} -o {} -gw {}\"\"\"\n",
    "#Uploading watershed dem to database\n",
    "rpg_cmd =               \"\"\"raster2pgsql -b 1 -s {} -d {} {} | PGPASSWORD={} psql -U {} -d {} -h {} -p 5432\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing watershed for a given dem projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing stations for epsg 32632 ...\n",
      "Langtjern, utløp\n",
      "Birkenes\n",
      "Øygardsbekken\n",
      "Storgama v. dam\n",
      "Kårvatn\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#Fetching all stations for a given projection\n",
    "epsg_num = 32632\n",
    "suffix = str(epsg_num)[-2:]\n",
    "cursor.execute(sql.SQL(\"\"\" SELECT station_id,station_name FROM {}.{}; \"\"\")\n",
    "                       .format(sql.Identifier(resultsSchema),\n",
    "                               sql.Identifier(dataTable + suffix)\n",
    "                               )\n",
    "               );\n",
    "conn.commit()\n",
    "rows=cursor.fetchall()\n",
    "tableName = 'results' + suffix\n",
    "print(\"Processing stations for epsg {} ...\".format(epsg_num))\n",
    "for row in rows:\n",
    "    sid = row[0]\n",
    "    station_name = row[1]\n",
    "    print(station_name)\n",
    "    #Getting dem with burned rivers (falling within buffersize)\n",
    "    subprocess.check_call(get_dem_cmd.format(credentials['host'],credentials['database'],credentials['username'],credentials['password'],\n",
    "                                             'basins','dem' + suffix,'river_rast','station_id='+str(sid), tempDir + 'el.tif'), shell=True, stdout=open(os.devnull, 'wb'))\n",
    "    #Filling dem\n",
    "    subprocess.check_call(fill_cmd.format(tempDir + 'el.tif', tempDir + 'fel.tif'),                                     shell=True, stdout=open(os.devnull, 'wb'))\n",
    "    #Get flow direction\n",
    "    subprocess.check_call(flow_dir_cmd.format(tempDir + 'fel.tif', tempDir + 'd8.tif'),                                 shell=True, stdout=open(os.devnull, 'wb'))\n",
    "    #Get flow accumulation\n",
    "    subprocess.check_call(flow_acc_cmd.format(tempDir + 'd8.tif', tempDir + 'flow_acc.tif'),                            shell=True, stdout=open(os.devnull, 'wb'))\n",
    "    #Getting station shapefile from postgis (necessary to specify the outlet in taudem)\n",
    "    subprocess.check_call(station_as_shp_cmd.format(tempDir + 'station', credentials['username'], credentials['password'], credentials['database'],\n",
    "                                                    'basins.dem' + suffix, sid),                                        shell=True, stdout=open(os.devnull, 'wb'))\n",
    "    #Computing watershed for outlet\n",
    "    subprocess.check_call(watershed_cmd.format(tempDir + 'd8.tif',tempDir + 'station.shp', tempDir + 'watershed.tif'),  shell=True, stdout=open(os.devnull, 'wb')) \n",
    "    #Uploading watershed raster to postgis\n",
    "    tempTable = 'dummy'\n",
    "    subprocess.check_call(rpg_cmd.format(str(epsg_num), tempDir + 'watershed.tif',resultsSchema + '.' + tempTable,\n",
    "                                         credentials['password'],credentials['username'],\n",
    "                                         credentials['database'],credentials['host']),                                  shell=True, stdout=open(os.devnull, 'wb')) \n",
    "    cursor.execute(sql.SQL(''' INSERT INTO {}.{}(station_id, station_name, rast)\n",
    "                                         SELECT b.station_id, b.station_name, ST_MapAlgebra(a.rast, '1BB', '[rast]') \n",
    "                                         FROM (SELECT station_id,station_name FROM basins.stations) as b, (SELECT rast FROM {}.{}) AS a\n",
    "                                         WHERE b.station_id=%s;\n",
    "                               DROP TABLE {}.{};         \n",
    "                              \n",
    "                           '''\n",
    "                           ).format(sql.Identifier(resultsSchema), sql.Identifier(tableName),\n",
    "                                    sql.Identifier(resultsSchema), sql.Identifier(tempTable), \n",
    "                                    sql.Identifier(resultsSchema), sql.Identifier(tempTable) ),                                          \n",
    "                   (sid,)\n",
    "                  )\n",
    "    conn.commit()\n",
    "    \n",
    "\n",
    "#Removing junk\n",
    "[os.remove(os.path.join('.',f)) for f in os.listdir('.') if f.endswith(\".tif\")]    \n",
    "    \n",
    "#Changing data type to boolean for watershed raster\n",
    "cursor.execute(sql.SQL('''  UPDATE {}.{}\n",
    "                             SET basin = ST_Polygon(rast);\n",
    "                            CREATE INDEX {} ON {}.{} USING GIST(basin);                         \n",
    "                       ''').format(sql.Identifier(resultsSchema), sql.Identifier(tableName),\n",
    "                                   sql.Identifier(tableName + '_idx'),\n",
    "                                   sql.Identifier(resultsSchema),sql.Identifier(tableName)\n",
    "                                  )           \n",
    "               )\n",
    "conn.commit();\n",
    "\n",
    "\n",
    "cursor.execute(sql.SQL('''  UPDATE {}.{} as b\n",
    "                             SET rast = ST_Clip(a.rast,basin)\n",
    "                                        FROM {}.{} AS a \n",
    "                                        WHERE b.station_id = a.station_id;\n",
    "                                                   \n",
    "                       '''\n",
    "                       ).format(sql.Identifier(resultsSchema), sql.Identifier(tableName),\n",
    "                                   sql.Identifier(resultsSchema) ,sql.Identifier('dem' + suffix)\n",
    "                               )           \n",
    "               )\n",
    "conn.commit();\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization\n",
    "\n",
    "The catchments will be displayed in google maps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Langtjern, utløp', 9.72672740897311, 60.3724668119067, 4447400.0)\n",
      "('Birkenes', 8.24164586793978, 58.3854634104195, 390900.0)\n",
      "('Øygardsbekken', 6.10640047729555, 58.6219112793301, 1748000.0)\n",
      "('Storgama v. dam', 8.65134235378551, 59.0501458751905, 227700.0)\n",
      "('Kårvatn', 8.89355815133143, 62.7828341592326, 23762900.0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b5d9b57d7154e2188f00e9efeaf5024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>Figure</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "Figure()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cursor.execute(\"\"\" SELECT json_build_object(\n",
    "                    'type', 'FeatureCollection',\n",
    "\n",
    "                    'features', json_agg(\n",
    "                        json_build_object(\n",
    "                            'type',       'Feature',\n",
    "                            'label',       station_name,\n",
    "                            'geometry',   ST_AsGeoJSON(ST_ForceRHR(st_transform(basin,4326)))::json,\n",
    "                            'properties', jsonb_set(row_to_json(results32)::jsonb,'{basin}','0',false)\n",
    "                             )\n",
    "                        )\n",
    "                   )\n",
    "                    FROM basins.results32;\n",
    "               \"\"\"\n",
    "              )\n",
    "\n",
    "\n",
    "rows=cursor.fetchall()\n",
    "fig = gmaps.figure()\n",
    "\n",
    "for row in rows :\n",
    "    basin_layer = gmaps.geojson_layer(row[0])\n",
    "    fig.add_layer(basin_layer)\n",
    "    \n",
    "    \n",
    "cursor.execute('''SELECT a.station_name, st_x(st_transform(a.outlet,4326)),\n",
    "                  st_y(st_transform(a.outlet,4326)), st_area(b.basin)\n",
    "                  FROM basins.dem32 AS a\n",
    "                  INNER JOIN basins.results32 AS b \n",
    "                  ON a.station_id = b.station_id;''')  \n",
    "\n",
    "rows=cursor.fetchall()\n",
    "\n",
    "outlets = []\n",
    "for row in rows:\n",
    "    print(row)\n",
    "    currentDict = {\"name\" : row[0], \"location\": (row[2],row[1]), \"area\": row[3]/1000000}\n",
    "    outlets.append(currentDict)\n",
    "\n",
    "outlet_locations = [outlet[\"location\"] for outlet in outlets]\n",
    "info_box_template = \"\"\"\n",
    "<dl>\n",
    "<dt>Name</dt><dd>{name}</dd>\n",
    "<dt>Area</dt><dd>{area}km2</dd>\n",
    "</dl>\n",
    "\"\"\"                                                \n",
    "outlet_info = [info_box_template.format(**outlet) for outlet in outlets]                                                 \n",
    "marker_layer = gmaps.marker_layer(outlet_locations, info_box_content=outlet_info)\n",
    "fig.add_layer(marker_layer)\n",
    "\n",
    "\n",
    "fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeating catchment delineation for a different projection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing stations for epsg 32633 ...\n",
      "Birkenes\n",
      "Øygardsbekken\n",
      "Storgama v. dam\n",
      "Dalelv\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#Creating folder to store intermediary results\n",
    "tempDir = './Trash/'\n",
    "if os.path.exists(tempDir) : \n",
    "    shutil.rmtree(tempDir)\n",
    "os.mkdir(tempDir)\n",
    "\n",
    "#Fetching all stations for a given projection\n",
    "epsg_num = 32633\n",
    "suffix = str(epsg_num)[-2:]\n",
    "cursor.execute(sql.SQL(\"\"\" SELECT station_id,station_name FROM {}.{}; \"\"\")\n",
    "                       .format(sql.Identifier(resultsSchema),\n",
    "                               sql.Identifier(dataTable + suffix)\n",
    "                               )\n",
    "               );\n",
    "conn.commit()\n",
    "rows=cursor.fetchall()\n",
    "tableName = 'results' + suffix\n",
    "print(\"Processing stations for epsg {} ...\".format(epsg_num))\n",
    "for row in rows:\n",
    "    sid = row[0]\n",
    "    station_name = row[1]\n",
    "    print(station_name)\n",
    "    #Getting dem with burned rivers (falling within buffersize)\n",
    "    subprocess.check_call(get_dem_cmd.format(credentials['host'],credentials['database'],credentials['username'],credentials['password'],\n",
    "                                             'basins','dem' + suffix,'river_rast','station_id='+str(sid), tempDir + 'el.tif'), shell=True, stdout=open(os.devnull, 'wb'))\n",
    "    #Filling dem\n",
    "    subprocess.check_call(fill_cmd.format(tempDir + 'el.tif', tempDir + 'fel.tif'),                                     shell=True, stdout=open(os.devnull, 'wb'))\n",
    "    #Get flow direction\n",
    "    subprocess.check_call(flow_dir_cmd.format(tempDir + 'fel.tif', tempDir + 'd8.tif'),                                 shell=True, stdout=open(os.devnull, 'wb'))\n",
    "    #Get flow accumulation\n",
    "    subprocess.check_call(flow_acc_cmd.format(tempDir + 'd8.tif', tempDir + 'flow_acc.tif'),                            shell=True, stdout=open(os.devnull, 'wb'))\n",
    "    #Getting station shapefile from postgis (necessary to specify the outlet in taudem)\n",
    "    subprocess.check_call(station_as_shp_cmd.format(tempDir + 'station', credentials['username'], credentials['password'], credentials['database'],\n",
    "                                                    'basins.dem' + suffix, sid),                                        shell=True, stdout=open(os.devnull, 'wb'))\n",
    "    #Computing watershed for outlet\n",
    "    subprocess.check_call(watershed_cmd.format(tempDir + 'd8.tif',tempDir + 'station.shp', tempDir + 'watershed.tif'),  shell=True, stdout=open(os.devnull, 'wb')) \n",
    "    #Uploading watershed raster to postgis\n",
    "    tempTable = 'dummy'\n",
    "    subprocess.check_call(rpg_cmd.format(str(epsg_num), tempDir + 'watershed.tif',resultsSchema + '.' + tempTable,\n",
    "                                         credentials['password'],credentials['username'],\n",
    "                                         credentials['database'],credentials['host']),                                  shell=True, stdout=open(os.devnull, 'wb')) \n",
    "    cursor.execute(sql.SQL(''' INSERT INTO {}.{}(station_id, station_name, rast)\n",
    "                                         SELECT b.station_id, b.station_name, ST_MapAlgebra(a.rast, '1BB', '[rast]') \n",
    "                                         FROM (SELECT station_id,station_name FROM basins.stations) as b, (SELECT rast FROM {}.{}) AS a\n",
    "                                         WHERE b.station_id=%s;\n",
    "                               DROP TABLE {}.{};         \n",
    "                              \n",
    "                           '''\n",
    "                           ).format(sql.Identifier(resultsSchema), sql.Identifier(tableName),\n",
    "                                    sql.Identifier(resultsSchema), sql.Identifier(tempTable), \n",
    "                                    sql.Identifier(resultsSchema), sql.Identifier(tempTable) ),                                          \n",
    "                   (sid,)\n",
    "                  )\n",
    "    conn.commit()\n",
    "    \n",
    "\n",
    "#Removing junk\n",
    "[os.remove(os.path.join('.',f)) for f in os.listdir('.') if f.endswith(\".tif\")]    \n",
    "    \n",
    "#Changing data type to boolean for watershed raster\n",
    "cursor.execute(sql.SQL('''  UPDATE {}.{}\n",
    "                             SET basin = ST_Polygon(rast);\n",
    "                            CREATE INDEX {} ON {}.{} USING GIST(basin);                         \n",
    "                       ''').format(sql.Identifier(resultsSchema), sql.Identifier(tableName),\n",
    "                                   sql.Identifier(tableName + '_idx'),\n",
    "                                   sql.Identifier(resultsSchema),sql.Identifier(tableName)\n",
    "                                  )           \n",
    "               )\n",
    "conn.commit();\n",
    "\n",
    "\n",
    "cursor.execute(sql.SQL('''  UPDATE {}.{} as b\n",
    "                             SET rast = ST_Clip(a.rast,basin)\n",
    "                                        FROM {}.{} AS a \n",
    "                                        WHERE b.station_id = a.station_id;\n",
    "                                                   \n",
    "                       '''\n",
    "                       ).format(sql.Identifier(resultsSchema), sql.Identifier(tableName),\n",
    "                                   sql.Identifier(resultsSchema) ,sql.Identifier('dem' + suffix)\n",
    "                               )           \n",
    "               )\n",
    "conn.commit();\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Birkenes', 8.2416458861021, 58.3854634023267, 389200.0)\n",
      "('Øygardsbekken', 6.10640070158926, 58.6219112411965, 1760700.0)\n",
      "('Storgama v. dam', 8.65134236427509, 59.0501458697299, 232100.0)\n",
      "('Dalelv', 30.3854943737806, 69.6846717648601, 1435700.0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2ded182d8bc491e9103c5f1fbe27a9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>Figure</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "Figure()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cursor.execute(\"\"\" SELECT json_build_object(\n",
    "                    'type', 'FeatureCollection',\n",
    "\n",
    "                    'features', json_agg(\n",
    "                        json_build_object(\n",
    "                            'type',       'Feature',\n",
    "                            'label',       station_name,\n",
    "                            'geometry',   ST_AsGeoJSON(ST_ForceRHR(st_transform(basin,4326)))::json,\n",
    "                            'properties', jsonb_set(row_to_json(results33)::jsonb,'{basin}','0',false)\n",
    "                             )\n",
    "                        )\n",
    "                   )\n",
    "                    FROM basins.results33;\n",
    "               \"\"\"\n",
    "              )\n",
    "\n",
    "\n",
    "rows=cursor.fetchall()\n",
    "fig = gmaps.figure()\n",
    "\n",
    "for row in rows :\n",
    "    basin_layer = gmaps.geojson_layer(row[0])\n",
    "    fig.add_layer(basin_layer)\n",
    "    \n",
    "    \n",
    "cursor.execute('''SELECT a.station_name, st_x(st_transform(a.outlet,4326)),\n",
    "                  st_y(st_transform(a.outlet,4326)), st_area(b.basin)\n",
    "                  FROM basins.dem33 AS a\n",
    "                  INNER JOIN basins.results33 AS b \n",
    "                  ON a.station_id = b.station_id;''')  \n",
    "\n",
    "rows=cursor.fetchall()\n",
    "\n",
    "outlets = []\n",
    "for row in rows:\n",
    "    print(row)\n",
    "    currentDict = {\"name\" : row[0], \"location\": (row[2],row[1]), \"area\": row[3]/1000000}\n",
    "    outlets.append(currentDict)\n",
    "\n",
    "outlet_locations = [outlet[\"location\"] for outlet in outlets]\n",
    "info_box_template = \"\"\"\n",
    "<dl>\n",
    "<dt>Name</dt><dd>{name}</dd>\n",
    "<dt>Area</dt><dd>{area}km2</dd>\n",
    "</dl>\n",
    "\"\"\"                                                \n",
    "outlet_info = [info_box_template.format(**outlet) for outlet in outlets]                                                 \n",
    "marker_layer = gmaps.marker_layer(outlet_locations, info_box_content=outlet_info)\n",
    "fig.add_layer(marker_layer)\n",
    "\n",
    "\n",
    "fig\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
